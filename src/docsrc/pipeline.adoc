= Pipeline

[sidebar]
{code-loc}/pipeline.sh[/pipeline.sh]

Baraa's project doesn't have any kind of automated pipeline, so I was a bit unsure about how
to run the scripts in a clean and automated way.
After briefly looking at Airflow,
I decided to write the ETL pipeline with Bash (`pipeline.sh`), since I started testing
things with `psql` on the command line and am not ready to dive into learning the Airflow
syntax just yet. Simple.

The `pipeline.sh` script calls SQL scripts run with psql, with output to the command line
and a log in `/tmp/sql-data-warehouse/`.

To run the full pipeline:

```
sudo -u postgres ./pipeline.sh full
```

There are other options besides 'full', if you want to run isolated stages of the pipeline.
Here are the stages each option runs:

[source,bash]
----
include::../../pipeline.sh[tag=options]
----


